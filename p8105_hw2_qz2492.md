p8105_hw2_qz2492
================
qz2492
2022-10-02

## Problem 1

``` r
# Read data and clean its names
NYC_T = read.csv('./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv') %>%
  janitor::clean_names()

# Check which columns got NULL values
NYC_T %>% naniar::miss_var_summary()
```

    ## # A tibble: 32 × 3
    ##    variable          n_miss pct_miss
    ##    <chr>              <int>    <dbl>
    ##  1 route10             1845     98.8
    ##  2 route11             1845     98.8
    ##  3 route9              1840     98.5
    ##  4 route8              1820     97.4
    ##  5 division               0      0  
    ##  6 line                   0      0  
    ##  7 station_name           0      0  
    ##  8 station_latitude       0      0  
    ##  9 station_longitude      0      0  
    ## 10 route1                 0      0  
    ## # … with 22 more rows

``` r
# Convert NULL values into chr to make route 8~11 consistent with others
NYC_T[is.na(NYC_T)] = '0'

# Select the columns we want and convert entry variable from chr to logical
NYC_T = select(NYC_T,
  line, station_name, station_latitude, station_longitude,
  starts_with("route"), entry, vending, entrance_type, ada
) %>% mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

This dataset mainly contains names and locations of every station, which
lines are they in, whether they have vending machines and equipment for
disabled. My cleaning steps include reading and cleaning names,
processing NULL values and selection for columns. The resulting dataset
has 1868 rows x 19 columns. And it is not tidy because of the redundance
in `route` variable.

``` r
NYC_T %>% 
  select(station_name, line) %>% 
  distinct
```

According to the code and output, there are 465 distinct stations.

``` r
NYC_T %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

According to the code and output, there are 84 ADA compliant stations.

``` r
NYC_T %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

According to the code and output, there are 37.7% station entrances /
exits without vending allow entrance.

``` r
NYC_T %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

According to the code and output, there are 60 distinct stations serving
the A train.

``` r
NYC_T %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

According to the code and output, there are 17 distinct stations serving
the A train and ADA compliant.

## Problem 2

``` r
# Read data and omit non-data entries
MrTW = read_excel('./data/Trash Wheel Collection Data.xlsx', sheet = "Mr. Trash Wheel", range = "A2:N550") %>% janitor::clean_names()

# omit rows that do not include dumpster-specific data
MrTW$dumpster = as.numeric(MrTW$dumpster)
MrTW = drop_na(MrTW, dumpster)

# round the number of sports balls
MrTW$sports_balls = as.integer(MrTW$sports_balls)
```

``` r
# Read data and omit non-data entries
ProfTW = read_excel('./data/Trash Wheel Collection Data.xlsx', sheet = "Professor Trash Wheel", range = "A2:M97") %>% janitor::clean_names()

# omit rows that do not include dumpster-specific data
ProfTW$dumpster = as.numeric(ProfTW$dumpster)
ProfTW = drop_na(ProfTW, dumpster)

# add a sports balls variable
ProfTW = add_column(ProfTW, sports_balls = 0, .before = "homes_powered")
```

``` r
# add a column in each tibble to identify them
MrTW = add_column(MrTW, sheet = 'Mr. Trash Wheel', .before = 1)
ProfTW = add_column(ProfTW, sheet = 'Professor Trash Wheel', .before = 1)

ProfTW$year = as.character(ProfTW$year)

# combining
CombinedTW = bind_rows(MrTW, ProfTW)
```

There are 547 rows, 15 columns and 8205 observations in *Mr. Trash Wheel
data set*, 94 rows, 15 columns and 1410 observations in *Professor Trash
Wheel data set*, and 641 rows, 15 columns and 9615 observations in
*Combined data set*. All of them have the same columns, `sheet`
indicating which sheets they belong to, `Dumpster` is the dumpster
number, `month`, `year`, `date` indicate the time when these dumpster
worked, `weight_tons` and `volume_cubic_yards` describe how much trash
each dumpster removed. For *Mr. Trash Wheel data set*, the *weight* is
from 0.78 to 5.62 tons, with the mean of 3.2 tons. For *Professor Trash
Wheel data set*, the *weight* is from 0.61 to 3.72 tons, with the mean
of 2.02 tons.  
For this data, the total weight of trash collected by Professor Trash
Wheel is 190.12 tons, the total number of sports balls collected by
Mr. Trash Wheel in 2020 is 856.

## Problem 3

``` r
pols_m = read.csv('./data/fivethirtyeight_datasets/pols-month.csv') %>%
  janitor::clean_names() %>%
  separate(mon, c("year", "month", "day"), sep = "-") %>%
  mutate(president = prez_gop,
         president = replace(president, president == 0, "republican"),
         president = replace(president, president == 1, "democratic"),
         president = factor(president)) %>%
  select(-prez_gop, -prez_dem, -day) %>%
  mutate(month = replace(month, month == "01", "jan"),
         month = replace(month, month == "02", "feb"),
         month = replace(month, month == "03", "mar"),
         month = replace(month, month == "04", "apr"),
         month = replace(month, month == "05", "may"),
         month = replace(month, month == "06", "jun"),
         month = replace(month, month == "07", "jul"),
         month = replace(month, month == "08", "aug"),
         month = replace(month, month == "09", "sep"),
         month = replace(month, month == "10", "oct"),
         month = replace(month, month == "11", "nov"),
         month = replace(month, month == "12", "dec"),)
```

``` r
snp = read.csv('./data/fivethirtyeight_datasets/snp.csv') %>%
  janitor::clean_names() %>%
  separate(date, c("day", "month", "year"), sep = "/") %>%
  select(-day) %>%
  mutate(month = replace(month, month == "1", "jan"),
         month = replace(month, month == "2", "feb"),
         month = replace(month, month == "3", "mar"),
         month = replace(month, month == "4", "apr")) %>%
  arrange(year, month) %>%
  relocate(year, month)

# make year variable consistent with former dataset
for (i in (1 : nrow(snp))){
  if(snp$year[i] < "50"){
    snp$year[i] = paste("20", snp$year[i], sep = "")
  }else {
    snp$year[i] = paste("19", snp$year[i], sep = "")
  }
}
```

``` r
unemp = read_csv('./data/fivethirtyeight_datasets/unemployment.csv') %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = 'month',
    values_to = 'percentage'
  ) 
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
tmp_ds = left_join(pols_m, snp, by = c("year", "month")) 
unemp$year = as.character(unemp$year)
joined_ds = left_join(tmp_ds, unemp, by = c("year", "month"))
```

For *pols_m* dataset, it contains 822 rows, 9 columns and 822
observations. The year variable ranges from *1947* to *2015*, the
*president* variable directly gives the which party the president was on
the associated day.

For *snp* dataset, it contains 787 rows, 3 columns and 787 observations.
The year variable ranges from *1950* to *2015*, the *close* variable
indicates the closing values of the *S&P stock index* on the associated
date.

For *unemp* dataset, it contains 816 rows, 3 columns and 816
observations. The year variable ranges from *1948* to *2015*, the
*percentage* variable indicates percentage of unemployment in the
associated month of the associated year.

For *joined_ds* dataset, it contains 1391 rows, 11 columns and 1391
observations.
